{"version":3,"sources":["webpack:///path----42b6f88096ed846992f3.js","webpack:///./.cache/json/layout-index.json"],"names":["webpackJsonp","259","module","exports","data","posts","edges","node","excerpt","fields","slug","prefix","frontmatter","title","subTitle","category","cover","children","__typename","resolutions","width","height","src","srcSet","srcWebp","srcSetWebp","pages","menuTitle","parts","html","layoutContext"],"mappings":"AAAAA,cAAc,iBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,MAAQC,OAASC,QAAUC,MAAQC,QAAA,wIAAAC,QAA4JC,KAAA,mBAAAC,OAAA,cAAgDC,aAAgBC,MAAA,iBAAAC,SAAA,KAAAC,SAAA,MAAAC,OAAmEC,WAAaC,WAAA,aAAAC,aAAyCC,MAAA,GAAAC,OAAA,GAAAC,IAAA,+DAAAC,OAAA,0QAAAC,QAAA,gEAAAC,WAAA,sRAA4tBlB,MAAQC,QAAA,GAAAC,QAAuBC,KAAA,sBAAAC,OAAA,cAAmDC,aAAgBC,MAAA,GAAAC,SAAA,KAAAC,SAAA,KAAAC,MAAA,SAA4DT,MAAQC,QAAA,qGAAAC,QAAyHC,KAAA,8BAAAC,OAAA,cAA2DC,aAAgBC,MAAA,oBAAAC,SAAA,KAAAC,SAAA,OAAAC,OAAuEC,WAAaC,WAAA,aAAAC,aAAyCC,MAAA,GAAAC,OAAA,GAAAC,IAAA,gEAAAC,OAAA,8QAAAC,QAAA,iEAAAC,WAAA,0RAAsuBlB,MAAQC,QAAA,IAAAC,QAAwBC,KAAA,+BAAAC,OAAA,cAA4DC,aAAgBC,MAAA,6BAAAC,SAAA,KAAAC,SAAA,MAAAC,OAA+EC,WAAaC,WAAA,aAAAC,aAAyCC,MAAA,GAAAC,OAAA,GAAAC,IAAA,+DAAAC,OAAA,0QAAAC,QAAA,gEAAAC,WAAA,sRAA4tBlB,MAAQC,QAAA,8IAAAC,QAAkKC,KAAA,iBAAAC,OAAA,cAA8CC,aAAgBC,MAAA,eAAAC,SAAA,sBAAAC,SAAA,SAAAC,OAAqFC,WAAaC,WAAA,aAAAC,aAAyCC,MAAA,GAAAC,OAAA,GAAAC,IAAA,iEAAAC,OAAA,8MAAAC,QAAA,kEAAAC,WAAA,yNAAumBlB,MAAQC,QAAA,qIAAAC,QAAyJC,KAAA,qCAAAC,OAAA,cAAkEC,aAAgBC,MAAA,8BAAAC,SAAA,uCAAAC,SAAA,KAAAC,OAAiHC,WAAaC,WAAA,aAAAC,aAAyCC,MAAA,GAAAC,OAAA,GAAAC,IAAA,iEAAAC,OAAA,kRAAAC,QAAA,kEAAAC,WAAA,8RAAgvBlB,MAAQC,QAAA,gIAAAC,QAAoJC,KAAA,wBAAAC,OAAA,cAAqDC,aAAgBC,MAAA,sBAAAC,SAAA,sBAAAC,SAAA,KAAAC,OAAwFC,WAAaC,WAAA,aAAAC,aAAyCC,MAAA,GAAAC,OAAA,GAAAC,IAAA,6DAAAC,OAAA,kMAAAC,QAAA,8DAAAC,WAAA,6MAAukBlB,MAAQC,QAAA,6IAAAC,QAAiKC,KAAA,mCAAAC,OAAA,cAAgEC,aAAgBC,MAAA,iCAAAC,SAAA,yBAAAC,SAAA,KAAAC,OAAsGC,WAAaC,WAAA,aAAAC,aAAyCC,MAAA,GAAAC,OAAA,GAAAC,IAAA,6DAAAC,OAAA,kMAAAC,QAAA,8DAAAC,WAAA,6MAAukBlB,MAAQC,QAAA,uGAAAC,QAA2HC,KAAA,wBAAAC,OAAA,cAAqDC,aAAgBC,MAAA,sBAAAC,SAAA,aAAAC,SAAA,KAAAC,OAA+EC,WAAaC,WAAA,aAAAC,aAAyCC,MAAA,GAAAC,OAAA,GAAAC,IAAA,wDAAAC,OAAA,8OAAAC,QAAA,yDAAAC,WAAA,0PAAspBlB,MAAQC,QAAA,kIAAAC,QAAsJC,KAAA,gDAAAC,OAAA,cAA6EC,aAAgBC,MAAA,+CAAAC,SAAA,kCAAAC,SAAA,KAAAC,OAA6HC,WAAaC,WAAA,aAAAC,aAAyCC,MAAA,GAAAC,OAAA,GAAAC,IAAA,8DAAAC,OAAA,sQAAAC,QAAA,+DAAAC,WAAA,kRAAktBlB,MAAQC,QAAA,gHAAAC,QAAoIC,KAAA,gDAAAC,OAAA,cAA6EC,aAAgBC,MAAA,8CAAAC,SAAA,mBAAAC,SAAA,KAAAC,OAA6GC,WAAaC,WAAA,aAAAC,aAAyCC,MAAA,GAAAC,OAAA,GAAAC,IAAA,wDAAAC,OAAA,8OAAAC,QAAA,yDAAAC,WAAA,2PAAspBC,OAAUpB,QAAUC,MAAQE,QAAUC,KAAA,UAAAC,OAAA,KAA8BC,aAAgBC,MAAA,QAAAc,UAAA,SAAqCpB,MAAQE,QAAUC,KAAA,gBAAAC,OAAA,KAAoCC,aAAgBC,MAAA,SAAAc,UAAA,kBAA8CC,OAAUtB,QAAUC,MAAQsB,KAAA,8BAAAjB,aAAoDC,MAAA,aAAqBN,MAAQsB,KAAA,gMAAAjB,aAA0NC,MAAA,eAAuBN,MAAQsB,KAAA,kFAAAjB,aAAwGC,MAAA,aAAoBiB","file":"path----42b6f88096ed846992f3.js","sourcesContent":["webpackJsonp([60335399758886],{\n\n/***/ 259:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"data\":{\"posts\":{\"edges\":[{\"node\":{\"excerpt\":\"在学习数字信号处理的时候，卷积是个让人又恨又爱的东西，一方面很难理解它的真实效果，初次接触非常难以建模，另一方面在信号处理中又十分常见。本文将介绍一下卷积的特点，以及离散系统的线性卷积和循环卷积运算，如何利用 FFT 计算卷积 1. 卷积 (convolution…\",\"fields\":{\"slug\":\"/1D-convolution/\",\"prefix\":\"2018-12-08\"},\"frontmatter\":{\"title\":\"1D convolution\",\"subTitle\":null,\"category\":\"DSP\",\"cover\":{\"children\":[{\"__typename\":\"ImageSharp\",\"resolutions\":{\"width\":90,\"height\":90,\"src\":\"/static/dsp-cover-380963b4c5d6d12b797ac84afca2db56-9e3e1.jpg\",\"srcSet\":\"/static/dsp-cover-380963b4c5d6d12b797ac84afca2db56-9e3e1.jpg 1x,\\n/static/dsp-cover-380963b4c5d6d12b797ac84afca2db56-670ee.jpg 1.5x,\\n/static/dsp-cover-380963b4c5d6d12b797ac84afca2db56-e72f0.jpg 2x,\\n/static/dsp-cover-380963b4c5d6d12b797ac84afca2db56-a0b5c.jpg 3x\",\"srcWebp\":\"/static/dsp-cover-380963b4c5d6d12b797ac84afca2db56-dc95d.webp\",\"srcSetWebp\":\"/static/dsp-cover-380963b4c5d6d12b797ac84afca2db56-dc95d.webp 1x,\\n/static/dsp-cover-380963b4c5d6d12b797ac84afca2db56-23c19.webp 1.5x,\\n/static/dsp-cover-380963b4c5d6d12b797ac84afca2db56-312b2.webp 2x,\\n/static/dsp-cover-380963b4c5d6d12b797ac84afca2db56-aa8fc.webp 3x\"}}]}}}},{\"node\":{\"excerpt\":\"\",\"fields\":{\"slug\":\"/matrix-derivative/\",\"prefix\":\"2018-12-08\"},\"frontmatter\":{\"title\":\"\",\"subTitle\":null,\"category\":null,\"cover\":null}}},{\"node\":{\"excerpt\":\"1. 矩阵偏导表示 首先要注意一个概念，numerator layout 和 denominator layout 的区别，下图展示了 6 种矩阵偏导的形式。但 numerator layout…\",\"fields\":{\"slug\":\"/matrix-derivative/.~index/\",\"prefix\":\"2018-12-08\"},\"frontmatter\":{\"title\":\"matrix derivative\",\"subTitle\":null,\"category\":\"math\",\"cover\":{\"children\":[{\"__typename\":\"ImageSharp\",\"resolutions\":{\"width\":90,\"height\":90,\"src\":\"/static/math-cover-e8ea255d97be55f4cfac0079c063f120-9e3e1.jpg\",\"srcSet\":\"/static/math-cover-e8ea255d97be55f4cfac0079c063f120-9e3e1.jpg 1x,\\n/static/math-cover-e8ea255d97be55f4cfac0079c063f120-670ee.jpg 1.5x,\\n/static/math-cover-e8ea255d97be55f4cfac0079c063f120-e72f0.jpg 2x,\\n/static/math-cover-e8ea255d97be55f4cfac0079c063f120-a0b5c.jpg 3x\",\"srcWebp\":\"/static/math-cover-e8ea255d97be55f4cfac0079c063f120-dc95d.webp\",\"srcSetWebp\":\"/static/math-cover-e8ea255d97be55f4cfac0079c063f120-dc95d.webp 1x,\\n/static/math-cover-e8ea255d97be55f4cfac0079c063f120-23c19.webp 1.5x,\\n/static/math-cover-e8ea255d97be55f4cfac0079c063f120-312b2.webp 2x,\\n/static/math-cover-e8ea255d97be55f4cfac0079c063f120-aa8fc.webp 3x\"}}]}}}},{\"node\":{\"excerpt\":\"…\",\"fields\":{\"slug\":\"/Thinking-of-2D-convolution/\",\"prefix\":\"2018-12-05\"},\"frontmatter\":{\"title\":\"Thinking of 2D convolution\",\"subTitle\":null,\"category\":\"DIP\",\"cover\":{\"children\":[{\"__typename\":\"ImageSharp\",\"resolutions\":{\"width\":90,\"height\":90,\"src\":\"/static/edge_conv-43097069e6b0f19a0c2658a8030e331b-6d4e8.png\",\"srcSet\":\"/static/edge_conv-43097069e6b0f19a0c2658a8030e331b-6d4e8.png 1x,\\n/static/edge_conv-43097069e6b0f19a0c2658a8030e331b-ded4e.png 1.5x,\\n/static/edge_conv-43097069e6b0f19a0c2658a8030e331b-59342.png 2x,\\n/static/edge_conv-43097069e6b0f19a0c2658a8030e331b-92edc.png 3x\",\"srcWebp\":\"/static/edge_conv-43097069e6b0f19a0c2658a8030e331b-9a16c.webp\",\"srcSetWebp\":\"/static/edge_conv-43097069e6b0f19a0c2658a8030e331b-9a16c.webp 1x,\\n/static/edge_conv-43097069e6b0f19a0c2658a8030e331b-c1dac.webp 1.5x,\\n/static/edge_conv-43097069e6b0f19a0c2658a8030e331b-cd83a.webp 2x,\\n/static/edge_conv-43097069e6b0f19a0c2658a8030e331b-abaa1.webp 3x\"}}]}}}},{\"node\":{\"excerpt\":\"本文主要介绍 Python 变量作用域 (Scope)。 1. 什么是 Scope 所谓作用域 (scope): 变量第一次赋值的位置决定了变量在代码中可见的范围，即变量能被使用的范围，这就是变量的作用域。  The place where you assign a name…\",\"fields\":{\"slug\":\"/python-scope/\",\"prefix\":\"2018-12-04\"},\"frontmatter\":{\"title\":\"Python scope\",\"subTitle\":\"Python 作用域 (变量使用范围)\",\"category\":\"python\",\"cover\":{\"children\":[{\"__typename\":\"ImageSharp\",\"resolutions\":{\"width\":90,\"height\":90,\"src\":\"/static/python_icon-c3425da5d7e58f0cf6ff6f59584493f2-9e3e1.jpg\",\"srcSet\":\"/static/python_icon-c3425da5d7e58f0cf6ff6f59584493f2-9e3e1.jpg 1x,\\n/static/python_icon-c3425da5d7e58f0cf6ff6f59584493f2-670ee.jpg 1.5x,\\n/static/python_icon-c3425da5d7e58f0cf6ff6f59584493f2-e72f0.jpg 2x\",\"srcWebp\":\"/static/python_icon-c3425da5d7e58f0cf6ff6f59584493f2-dc95d.webp\",\"srcSetWebp\":\"/static/python_icon-c3425da5d7e58f0cf6ff6f59584493f2-dc95d.webp 1x,\\n/static/python_icon-c3425da5d7e58f0cf6ff6f59584493f2-23c19.webp 1.5x,\\n/static/python_icon-c3425da5d7e58f0cf6ff6f59584493f2-312b2.webp 2x\"}}]}}}},{\"node\":{\"excerpt\":\"1. 安装 Ubuntu 16.04 这一步就不说了，网上很多教程，几点建议:  请不要尝试 Ubuntu 18.04，新版本 bug 比较多 下载地址:  Ubuntu 16.04 Desktop (64-bit) 系统语言选英文，主要是有助于 shell…\",\"fields\":{\"slug\":\"/Ubuntu-16.04-cuda-+-pytorch/inde/\",\"prefix\":\"2018-12-04\"},\"frontmatter\":{\"title\":\"Ubuntu 16.04 cuda + pytorch\",\"subTitle\":\"Ubuntu 16.04 系统 安装 cuda , pytorch 流程\",\"category\":\"AI\",\"cover\":{\"children\":[{\"__typename\":\"ImageSharp\",\"resolutions\":{\"width\":90,\"height\":90,\"src\":\"/static/NVIDIA_CUDA-a8eed72c9503cf265dbb6f5ed84d0400-9e3e1.jpg\",\"srcSet\":\"/static/NVIDIA_CUDA-a8eed72c9503cf265dbb6f5ed84d0400-9e3e1.jpg 1x,\\n/static/NVIDIA_CUDA-a8eed72c9503cf265dbb6f5ed84d0400-670ee.jpg 1.5x,\\n/static/NVIDIA_CUDA-a8eed72c9503cf265dbb6f5ed84d0400-e72f0.jpg 2x,\\n/static/NVIDIA_CUDA-a8eed72c9503cf265dbb6f5ed84d0400-a0b5c.jpg 3x\",\"srcWebp\":\"/static/NVIDIA_CUDA-a8eed72c9503cf265dbb6f5ed84d0400-dc95d.webp\",\"srcSetWebp\":\"/static/NVIDIA_CUDA-a8eed72c9503cf265dbb6f5ed84d0400-dc95d.webp 1x,\\n/static/NVIDIA_CUDA-a8eed72c9503cf265dbb6f5ed84d0400-23c19.webp 1.5x,\\n/static/NVIDIA_CUDA-a8eed72c9503cf265dbb6f5ed84d0400-312b2.webp 2x,\\n/static/NVIDIA_CUDA-a8eed72c9503cf265dbb6f5ed84d0400-aa8fc.webp 3x\"}}]}}}},{\"node\":{\"excerpt\":\"在了解 全连接层反向传播的机理后，我在 Google 上找了一圈，都没有找到讲得很好的 CNN 反向传播的计算，本想通过研究 Pytorch 源码分析算法原理，发现 Pytorch 底层是调用 C 代码的，也就不了了之了。最近在学习 Darknet…\",\"fields\":{\"slug\":\"/DarkNet-CNN-Analyse/\",\"prefix\":\"2018-12-04\"},\"frontmatter\":{\"title\":\"DarkNet CNN Analyse\",\"subTitle\":\"介绍 DarkNet CNN 实现原理\",\"category\":\"AI\",\"cover\":{\"children\":[{\"__typename\":\"ImageSharp\",\"resolutions\":{\"width\":90,\"height\":90,\"src\":\"/static/darknet-a128141842710e6137de63943fa20758-6d4e8.png\",\"srcSet\":\"/static/darknet-a128141842710e6137de63943fa20758-6d4e8.png 1x,\\n/static/darknet-a128141842710e6137de63943fa20758-ded4e.png 1.5x,\\n/static/darknet-a128141842710e6137de63943fa20758-59342.png 2x\",\"srcWebp\":\"/static/darknet-a128141842710e6137de63943fa20758-9a16c.webp\",\"srcSetWebp\":\"/static/darknet-a128141842710e6137de63943fa20758-9a16c.webp 1x,\\n/static/darknet-a128141842710e6137de63943fa20758-c1dac.webp 1.5x,\\n/static/darknet-a128141842710e6137de63943fa20758-cd83a.webp 2x\"}}]}}}},{\"node\":{\"excerpt\":\"最近在看 YoLo 源码的时候，发现原作者使用的是一个叫 DarkNet 的神经网络库，地址如下:  https://github.com/pjreddie/darknet Darknet is an open source neural network framework…\",\"fields\":{\"slug\":\"/DarkNet-Framework-Introduction/\",\"prefix\":\"2018-12-04\"},\"frontmatter\":{\"title\":\"DarkNet Framework Introduction\",\"subTitle\":\"介绍 DarkNet 神经网络框架的源码实现\",\"category\":\"AI\",\"cover\":{\"children\":[{\"__typename\":\"ImageSharp\",\"resolutions\":{\"width\":90,\"height\":90,\"src\":\"/static/darknet-a128141842710e6137de63943fa20758-6d4e8.png\",\"srcSet\":\"/static/darknet-a128141842710e6137de63943fa20758-6d4e8.png 1x,\\n/static/darknet-a128141842710e6137de63943fa20758-ded4e.png 1.5x,\\n/static/darknet-a128141842710e6137de63943fa20758-59342.png 2x\",\"srcWebp\":\"/static/darknet-a128141842710e6137de63943fa20758-9a16c.webp\",\"srcSetWebp\":\"/static/darknet-a128141842710e6137de63943fa20758-9a16c.webp 1x,\\n/static/darknet-a128141842710e6137de63943fa20758-c1dac.webp 1.5x,\\n/static/darknet-a128141842710e6137de63943fa20758-cd83a.webp 2x\"}}]}}}},{\"node\":{\"excerpt\":\"1. Python 入门篇 廖雪峰的 Python 教程   推荐看到 正则表达式就可以了，前面如果不懂，可以利用丰富的网上资源查找资料，不用只局限一篇博客 书籍:  Learning Python…\",\"fields\":{\"slug\":\"/AI-ML-Learning-Path/\",\"prefix\":\"2018-12-04\"},\"frontmatter\":{\"title\":\"AI ML Learning Path\",\"subTitle\":\"机器学习新手学习路线\",\"category\":\"AI\",\"cover\":{\"children\":[{\"__typename\":\"ImageSharp\",\"resolutions\":{\"width\":90,\"height\":90,\"src\":\"/static/ai-f89a04b44bc8c4f392f9256e7c1a247c-9e3e1.jpg\",\"srcSet\":\"/static/ai-f89a04b44bc8c4f392f9256e7c1a247c-9e3e1.jpg 1x,\\n/static/ai-f89a04b44bc8c4f392f9256e7c1a247c-670ee.jpg 1.5x,\\n/static/ai-f89a04b44bc8c4f392f9256e7c1a247c-e72f0.jpg 2x,\\n/static/ai-f89a04b44bc8c4f392f9256e7c1a247c-a0b5c.jpg 3x\",\"srcWebp\":\"/static/ai-f89a04b44bc8c4f392f9256e7c1a247c-dc95d.webp\",\"srcSetWebp\":\"/static/ai-f89a04b44bc8c4f392f9256e7c1a247c-dc95d.webp 1x,\\n/static/ai-f89a04b44bc8c4f392f9256e7c1a247c-23c19.webp 1.5x,\\n/static/ai-f89a04b44bc8c4f392f9256e7c1a247c-312b2.webp 2x,\\n/static/ai-f89a04b44bc8c4f392f9256e7c1a247c-aa8fc.webp 3x\"}}]}}}},{\"node\":{\"excerpt\":\"之前的一篇博客  利用 matrix derivative 思考 back propagation  介绍了反向传播的公式推导。 主要公式如下:  看完公式，你应该知道，根据梯度下降，如果我们想更新第   层的   (weight) 和   (bias…\",\"fields\":{\"slug\":\"/a-primary-neural-network-framwork-by-python/\",\"prefix\":\"2018-12-04\"},\"frontmatter\":{\"title\":\"a primary neural network framework by python\",\"subTitle\":\"使用 Python 编写的一个初步的神经网络框架，包含后向传播\",\"category\":\"AI\",\"cover\":{\"children\":[{\"__typename\":\"ImageSharp\",\"resolutions\":{\"width\":90,\"height\":90,\"src\":\"/static/nn-cover-6ccbad2ba089eb26d198108e2aac6872-6d4e8.png\",\"srcSet\":\"/static/nn-cover-6ccbad2ba089eb26d198108e2aac6872-6d4e8.png 1x,\\n/static/nn-cover-6ccbad2ba089eb26d198108e2aac6872-ded4e.png 1.5x,\\n/static/nn-cover-6ccbad2ba089eb26d198108e2aac6872-59342.png 2x,\\n/static/nn-cover-6ccbad2ba089eb26d198108e2aac6872-92edc.png 3x\",\"srcWebp\":\"/static/nn-cover-6ccbad2ba089eb26d198108e2aac6872-9a16c.webp\",\"srcSetWebp\":\"/static/nn-cover-6ccbad2ba089eb26d198108e2aac6872-9a16c.webp 1x,\\n/static/nn-cover-6ccbad2ba089eb26d198108e2aac6872-c1dac.webp 1.5x,\\n/static/nn-cover-6ccbad2ba089eb26d198108e2aac6872-cd83a.webp 2x,\\n/static/nn-cover-6ccbad2ba089eb26d198108e2aac6872-abaa1.webp 3x\"}}]}}}},{\"node\":{\"excerpt\":\"在之前  矩阵偏导  一文中提到，我们通常采用 numerator layout 的格式表示偏导矩阵。 但是 !!!!!! 在 back propagation 中，我们应当采用 denominator layout…\",\"fields\":{\"slug\":\"/Back-propagation-based-on-matrix-derivative/\",\"prefix\":\"2018-12-04\"},\"frontmatter\":{\"title\":\"Back propagation bases on matrix derivatite\",\"subTitle\":\"利用矩阵偏导公式推导后向传播算法\",\"category\":\"AI\",\"cover\":{\"children\":[{\"__typename\":\"ImageSharp\",\"resolutions\":{\"width\":90,\"height\":90,\"src\":\"/static/bp-2c1d7428583927bc8ad4c2f14d770b75-9e3e1.jpg\",\"srcSet\":\"/static/bp-2c1d7428583927bc8ad4c2f14d770b75-9e3e1.jpg 1x,\\n/static/bp-2c1d7428583927bc8ad4c2f14d770b75-670ee.jpg 1.5x,\\n/static/bp-2c1d7428583927bc8ad4c2f14d770b75-e72f0.jpg 2x,\\n/static/bp-2c1d7428583927bc8ad4c2f14d770b75-a0b5c.jpg 3x\",\"srcWebp\":\"/static/bp-2c1d7428583927bc8ad4c2f14d770b75-dc95d.webp\",\"srcSetWebp\":\"/static/bp-2c1d7428583927bc8ad4c2f14d770b75-dc95d.webp 1x,\\n/static/bp-2c1d7428583927bc8ad4c2f14d770b75-23c19.webp 1.5x,\\n/static/bp-2c1d7428583927bc8ad4c2f14d770b75-312b2.webp 2x,\\n/static/bp-2c1d7428583927bc8ad4c2f14d770b75-aa8fc.webp 3x\"}}]}}}}]},\"pages\":{\"edges\":[{\"node\":{\"fields\":{\"slug\":\"/about/\",\"prefix\":\"1\"},\"frontmatter\":{\"title\":\"About\",\"menuTitle\":null}}},{\"node\":{\"fields\":{\"slug\":\"/cheatsheets/\",\"prefix\":\"2\"},\"frontmatter\":{\"title\":\"快捷键和命令\",\"menuTitle\":\"Cheatsheet\"}}}]},\"parts\":{\"edges\":[{\"node\":{\"html\":\"<p>我是一名数据工程师，对硬件有浓厚的兴趣。</p>\",\"frontmatter\":{\"title\":\"author\"}}},{\"node\":{\"html\":\"<ul>\\n<li>this is a site built by <a href=\\\"https://www.gatsbyjs.org/\\\">GatsbyJS</a>, ReactJs, CSS in JS</li>\\n<li>delivered by <a href=\\\"https://pages.github.com/\\\">Github Page</a></li>\\n</ul>\",\"frontmatter\":{\"title\":\"footnote\"}}},{\"node\":{\"html\":\"<p>I am a data-science engineer with also interests in React and Hardware. </p>\",\"frontmatter\":{\"title\":\"info\"}}}]}},\"layoutContext\":{}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path----42b6f88096ed846992f3.js","module.exports = {\"data\":{\"posts\":{\"edges\":[{\"node\":{\"excerpt\":\"在学习数字信号处理的时候，卷积是个让人又恨又爱的东西，一方面很难理解它的真实效果，初次接触非常难以建模，另一方面在信号处理中又十分常见。本文将介绍一下卷积的特点，以及离散系统的线性卷积和循环卷积运算，如何利用 FFT 计算卷积 1. 卷积 (convolution…\",\"fields\":{\"slug\":\"/1D-convolution/\",\"prefix\":\"2018-12-08\"},\"frontmatter\":{\"title\":\"1D convolution\",\"subTitle\":null,\"category\":\"DSP\",\"cover\":{\"children\":[{\"__typename\":\"ImageSharp\",\"resolutions\":{\"width\":90,\"height\":90,\"src\":\"/static/dsp-cover-380963b4c5d6d12b797ac84afca2db56-9e3e1.jpg\",\"srcSet\":\"/static/dsp-cover-380963b4c5d6d12b797ac84afca2db56-9e3e1.jpg 1x,\\n/static/dsp-cover-380963b4c5d6d12b797ac84afca2db56-670ee.jpg 1.5x,\\n/static/dsp-cover-380963b4c5d6d12b797ac84afca2db56-e72f0.jpg 2x,\\n/static/dsp-cover-380963b4c5d6d12b797ac84afca2db56-a0b5c.jpg 3x\",\"srcWebp\":\"/static/dsp-cover-380963b4c5d6d12b797ac84afca2db56-dc95d.webp\",\"srcSetWebp\":\"/static/dsp-cover-380963b4c5d6d12b797ac84afca2db56-dc95d.webp 1x,\\n/static/dsp-cover-380963b4c5d6d12b797ac84afca2db56-23c19.webp 1.5x,\\n/static/dsp-cover-380963b4c5d6d12b797ac84afca2db56-312b2.webp 2x,\\n/static/dsp-cover-380963b4c5d6d12b797ac84afca2db56-aa8fc.webp 3x\"}}]}}}},{\"node\":{\"excerpt\":\"\",\"fields\":{\"slug\":\"/matrix-derivative/\",\"prefix\":\"2018-12-08\"},\"frontmatter\":{\"title\":\"\",\"subTitle\":null,\"category\":null,\"cover\":null}}},{\"node\":{\"excerpt\":\"1. 矩阵偏导表示 首先要注意一个概念，numerator layout 和 denominator layout 的区别，下图展示了 6 种矩阵偏导的形式。但 numerator layout…\",\"fields\":{\"slug\":\"/matrix-derivative/.~index/\",\"prefix\":\"2018-12-08\"},\"frontmatter\":{\"title\":\"matrix derivative\",\"subTitle\":null,\"category\":\"math\",\"cover\":{\"children\":[{\"__typename\":\"ImageSharp\",\"resolutions\":{\"width\":90,\"height\":90,\"src\":\"/static/math-cover-e8ea255d97be55f4cfac0079c063f120-9e3e1.jpg\",\"srcSet\":\"/static/math-cover-e8ea255d97be55f4cfac0079c063f120-9e3e1.jpg 1x,\\n/static/math-cover-e8ea255d97be55f4cfac0079c063f120-670ee.jpg 1.5x,\\n/static/math-cover-e8ea255d97be55f4cfac0079c063f120-e72f0.jpg 2x,\\n/static/math-cover-e8ea255d97be55f4cfac0079c063f120-a0b5c.jpg 3x\",\"srcWebp\":\"/static/math-cover-e8ea255d97be55f4cfac0079c063f120-dc95d.webp\",\"srcSetWebp\":\"/static/math-cover-e8ea255d97be55f4cfac0079c063f120-dc95d.webp 1x,\\n/static/math-cover-e8ea255d97be55f4cfac0079c063f120-23c19.webp 1.5x,\\n/static/math-cover-e8ea255d97be55f4cfac0079c063f120-312b2.webp 2x,\\n/static/math-cover-e8ea255d97be55f4cfac0079c063f120-aa8fc.webp 3x\"}}]}}}},{\"node\":{\"excerpt\":\"…\",\"fields\":{\"slug\":\"/Thinking-of-2D-convolution/\",\"prefix\":\"2018-12-05\"},\"frontmatter\":{\"title\":\"Thinking of 2D convolution\",\"subTitle\":null,\"category\":\"DIP\",\"cover\":{\"children\":[{\"__typename\":\"ImageSharp\",\"resolutions\":{\"width\":90,\"height\":90,\"src\":\"/static/edge_conv-43097069e6b0f19a0c2658a8030e331b-6d4e8.png\",\"srcSet\":\"/static/edge_conv-43097069e6b0f19a0c2658a8030e331b-6d4e8.png 1x,\\n/static/edge_conv-43097069e6b0f19a0c2658a8030e331b-ded4e.png 1.5x,\\n/static/edge_conv-43097069e6b0f19a0c2658a8030e331b-59342.png 2x,\\n/static/edge_conv-43097069e6b0f19a0c2658a8030e331b-92edc.png 3x\",\"srcWebp\":\"/static/edge_conv-43097069e6b0f19a0c2658a8030e331b-9a16c.webp\",\"srcSetWebp\":\"/static/edge_conv-43097069e6b0f19a0c2658a8030e331b-9a16c.webp 1x,\\n/static/edge_conv-43097069e6b0f19a0c2658a8030e331b-c1dac.webp 1.5x,\\n/static/edge_conv-43097069e6b0f19a0c2658a8030e331b-cd83a.webp 2x,\\n/static/edge_conv-43097069e6b0f19a0c2658a8030e331b-abaa1.webp 3x\"}}]}}}},{\"node\":{\"excerpt\":\"本文主要介绍 Python 变量作用域 (Scope)。 1. 什么是 Scope 所谓作用域 (scope): 变量第一次赋值的位置决定了变量在代码中可见的范围，即变量能被使用的范围，这就是变量的作用域。  The place where you assign a name…\",\"fields\":{\"slug\":\"/python-scope/\",\"prefix\":\"2018-12-04\"},\"frontmatter\":{\"title\":\"Python scope\",\"subTitle\":\"Python 作用域 (变量使用范围)\",\"category\":\"python\",\"cover\":{\"children\":[{\"__typename\":\"ImageSharp\",\"resolutions\":{\"width\":90,\"height\":90,\"src\":\"/static/python_icon-c3425da5d7e58f0cf6ff6f59584493f2-9e3e1.jpg\",\"srcSet\":\"/static/python_icon-c3425da5d7e58f0cf6ff6f59584493f2-9e3e1.jpg 1x,\\n/static/python_icon-c3425da5d7e58f0cf6ff6f59584493f2-670ee.jpg 1.5x,\\n/static/python_icon-c3425da5d7e58f0cf6ff6f59584493f2-e72f0.jpg 2x\",\"srcWebp\":\"/static/python_icon-c3425da5d7e58f0cf6ff6f59584493f2-dc95d.webp\",\"srcSetWebp\":\"/static/python_icon-c3425da5d7e58f0cf6ff6f59584493f2-dc95d.webp 1x,\\n/static/python_icon-c3425da5d7e58f0cf6ff6f59584493f2-23c19.webp 1.5x,\\n/static/python_icon-c3425da5d7e58f0cf6ff6f59584493f2-312b2.webp 2x\"}}]}}}},{\"node\":{\"excerpt\":\"1. 安装 Ubuntu 16.04 这一步就不说了，网上很多教程，几点建议:  请不要尝试 Ubuntu 18.04，新版本 bug 比较多 下载地址:  Ubuntu 16.04 Desktop (64-bit) 系统语言选英文，主要是有助于 shell…\",\"fields\":{\"slug\":\"/Ubuntu-16.04-cuda-+-pytorch/inde/\",\"prefix\":\"2018-12-04\"},\"frontmatter\":{\"title\":\"Ubuntu 16.04 cuda + pytorch\",\"subTitle\":\"Ubuntu 16.04 系统 安装 cuda , pytorch 流程\",\"category\":\"AI\",\"cover\":{\"children\":[{\"__typename\":\"ImageSharp\",\"resolutions\":{\"width\":90,\"height\":90,\"src\":\"/static/NVIDIA_CUDA-a8eed72c9503cf265dbb6f5ed84d0400-9e3e1.jpg\",\"srcSet\":\"/static/NVIDIA_CUDA-a8eed72c9503cf265dbb6f5ed84d0400-9e3e1.jpg 1x,\\n/static/NVIDIA_CUDA-a8eed72c9503cf265dbb6f5ed84d0400-670ee.jpg 1.5x,\\n/static/NVIDIA_CUDA-a8eed72c9503cf265dbb6f5ed84d0400-e72f0.jpg 2x,\\n/static/NVIDIA_CUDA-a8eed72c9503cf265dbb6f5ed84d0400-a0b5c.jpg 3x\",\"srcWebp\":\"/static/NVIDIA_CUDA-a8eed72c9503cf265dbb6f5ed84d0400-dc95d.webp\",\"srcSetWebp\":\"/static/NVIDIA_CUDA-a8eed72c9503cf265dbb6f5ed84d0400-dc95d.webp 1x,\\n/static/NVIDIA_CUDA-a8eed72c9503cf265dbb6f5ed84d0400-23c19.webp 1.5x,\\n/static/NVIDIA_CUDA-a8eed72c9503cf265dbb6f5ed84d0400-312b2.webp 2x,\\n/static/NVIDIA_CUDA-a8eed72c9503cf265dbb6f5ed84d0400-aa8fc.webp 3x\"}}]}}}},{\"node\":{\"excerpt\":\"在了解 全连接层反向传播的机理后，我在 Google 上找了一圈，都没有找到讲得很好的 CNN 反向传播的计算，本想通过研究 Pytorch 源码分析算法原理，发现 Pytorch 底层是调用 C 代码的，也就不了了之了。最近在学习 Darknet…\",\"fields\":{\"slug\":\"/DarkNet-CNN-Analyse/\",\"prefix\":\"2018-12-04\"},\"frontmatter\":{\"title\":\"DarkNet CNN Analyse\",\"subTitle\":\"介绍 DarkNet CNN 实现原理\",\"category\":\"AI\",\"cover\":{\"children\":[{\"__typename\":\"ImageSharp\",\"resolutions\":{\"width\":90,\"height\":90,\"src\":\"/static/darknet-a128141842710e6137de63943fa20758-6d4e8.png\",\"srcSet\":\"/static/darknet-a128141842710e6137de63943fa20758-6d4e8.png 1x,\\n/static/darknet-a128141842710e6137de63943fa20758-ded4e.png 1.5x,\\n/static/darknet-a128141842710e6137de63943fa20758-59342.png 2x\",\"srcWebp\":\"/static/darknet-a128141842710e6137de63943fa20758-9a16c.webp\",\"srcSetWebp\":\"/static/darknet-a128141842710e6137de63943fa20758-9a16c.webp 1x,\\n/static/darknet-a128141842710e6137de63943fa20758-c1dac.webp 1.5x,\\n/static/darknet-a128141842710e6137de63943fa20758-cd83a.webp 2x\"}}]}}}},{\"node\":{\"excerpt\":\"最近在看 YoLo 源码的时候，发现原作者使用的是一个叫 DarkNet 的神经网络库，地址如下:  https://github.com/pjreddie/darknet Darknet is an open source neural network framework…\",\"fields\":{\"slug\":\"/DarkNet-Framework-Introduction/\",\"prefix\":\"2018-12-04\"},\"frontmatter\":{\"title\":\"DarkNet Framework Introduction\",\"subTitle\":\"介绍 DarkNet 神经网络框架的源码实现\",\"category\":\"AI\",\"cover\":{\"children\":[{\"__typename\":\"ImageSharp\",\"resolutions\":{\"width\":90,\"height\":90,\"src\":\"/static/darknet-a128141842710e6137de63943fa20758-6d4e8.png\",\"srcSet\":\"/static/darknet-a128141842710e6137de63943fa20758-6d4e8.png 1x,\\n/static/darknet-a128141842710e6137de63943fa20758-ded4e.png 1.5x,\\n/static/darknet-a128141842710e6137de63943fa20758-59342.png 2x\",\"srcWebp\":\"/static/darknet-a128141842710e6137de63943fa20758-9a16c.webp\",\"srcSetWebp\":\"/static/darknet-a128141842710e6137de63943fa20758-9a16c.webp 1x,\\n/static/darknet-a128141842710e6137de63943fa20758-c1dac.webp 1.5x,\\n/static/darknet-a128141842710e6137de63943fa20758-cd83a.webp 2x\"}}]}}}},{\"node\":{\"excerpt\":\"1. Python 入门篇 廖雪峰的 Python 教程   推荐看到 正则表达式就可以了，前面如果不懂，可以利用丰富的网上资源查找资料，不用只局限一篇博客 书籍:  Learning Python…\",\"fields\":{\"slug\":\"/AI-ML-Learning-Path/\",\"prefix\":\"2018-12-04\"},\"frontmatter\":{\"title\":\"AI ML Learning Path\",\"subTitle\":\"机器学习新手学习路线\",\"category\":\"AI\",\"cover\":{\"children\":[{\"__typename\":\"ImageSharp\",\"resolutions\":{\"width\":90,\"height\":90,\"src\":\"/static/ai-f89a04b44bc8c4f392f9256e7c1a247c-9e3e1.jpg\",\"srcSet\":\"/static/ai-f89a04b44bc8c4f392f9256e7c1a247c-9e3e1.jpg 1x,\\n/static/ai-f89a04b44bc8c4f392f9256e7c1a247c-670ee.jpg 1.5x,\\n/static/ai-f89a04b44bc8c4f392f9256e7c1a247c-e72f0.jpg 2x,\\n/static/ai-f89a04b44bc8c4f392f9256e7c1a247c-a0b5c.jpg 3x\",\"srcWebp\":\"/static/ai-f89a04b44bc8c4f392f9256e7c1a247c-dc95d.webp\",\"srcSetWebp\":\"/static/ai-f89a04b44bc8c4f392f9256e7c1a247c-dc95d.webp 1x,\\n/static/ai-f89a04b44bc8c4f392f9256e7c1a247c-23c19.webp 1.5x,\\n/static/ai-f89a04b44bc8c4f392f9256e7c1a247c-312b2.webp 2x,\\n/static/ai-f89a04b44bc8c4f392f9256e7c1a247c-aa8fc.webp 3x\"}}]}}}},{\"node\":{\"excerpt\":\"之前的一篇博客  利用 matrix derivative 思考 back propagation  介绍了反向传播的公式推导。 主要公式如下:  看完公式，你应该知道，根据梯度下降，如果我们想更新第   层的   (weight) 和   (bias…\",\"fields\":{\"slug\":\"/a-primary-neural-network-framwork-by-python/\",\"prefix\":\"2018-12-04\"},\"frontmatter\":{\"title\":\"a primary neural network framework by python\",\"subTitle\":\"使用 Python 编写的一个初步的神经网络框架，包含后向传播\",\"category\":\"AI\",\"cover\":{\"children\":[{\"__typename\":\"ImageSharp\",\"resolutions\":{\"width\":90,\"height\":90,\"src\":\"/static/nn-cover-6ccbad2ba089eb26d198108e2aac6872-6d4e8.png\",\"srcSet\":\"/static/nn-cover-6ccbad2ba089eb26d198108e2aac6872-6d4e8.png 1x,\\n/static/nn-cover-6ccbad2ba089eb26d198108e2aac6872-ded4e.png 1.5x,\\n/static/nn-cover-6ccbad2ba089eb26d198108e2aac6872-59342.png 2x,\\n/static/nn-cover-6ccbad2ba089eb26d198108e2aac6872-92edc.png 3x\",\"srcWebp\":\"/static/nn-cover-6ccbad2ba089eb26d198108e2aac6872-9a16c.webp\",\"srcSetWebp\":\"/static/nn-cover-6ccbad2ba089eb26d198108e2aac6872-9a16c.webp 1x,\\n/static/nn-cover-6ccbad2ba089eb26d198108e2aac6872-c1dac.webp 1.5x,\\n/static/nn-cover-6ccbad2ba089eb26d198108e2aac6872-cd83a.webp 2x,\\n/static/nn-cover-6ccbad2ba089eb26d198108e2aac6872-abaa1.webp 3x\"}}]}}}},{\"node\":{\"excerpt\":\"在之前  矩阵偏导  一文中提到，我们通常采用 numerator layout 的格式表示偏导矩阵。 但是 !!!!!! 在 back propagation 中，我们应当采用 denominator layout…\",\"fields\":{\"slug\":\"/Back-propagation-based-on-matrix-derivative/\",\"prefix\":\"2018-12-04\"},\"frontmatter\":{\"title\":\"Back propagation bases on matrix derivatite\",\"subTitle\":\"利用矩阵偏导公式推导后向传播算法\",\"category\":\"AI\",\"cover\":{\"children\":[{\"__typename\":\"ImageSharp\",\"resolutions\":{\"width\":90,\"height\":90,\"src\":\"/static/bp-2c1d7428583927bc8ad4c2f14d770b75-9e3e1.jpg\",\"srcSet\":\"/static/bp-2c1d7428583927bc8ad4c2f14d770b75-9e3e1.jpg 1x,\\n/static/bp-2c1d7428583927bc8ad4c2f14d770b75-670ee.jpg 1.5x,\\n/static/bp-2c1d7428583927bc8ad4c2f14d770b75-e72f0.jpg 2x,\\n/static/bp-2c1d7428583927bc8ad4c2f14d770b75-a0b5c.jpg 3x\",\"srcWebp\":\"/static/bp-2c1d7428583927bc8ad4c2f14d770b75-dc95d.webp\",\"srcSetWebp\":\"/static/bp-2c1d7428583927bc8ad4c2f14d770b75-dc95d.webp 1x,\\n/static/bp-2c1d7428583927bc8ad4c2f14d770b75-23c19.webp 1.5x,\\n/static/bp-2c1d7428583927bc8ad4c2f14d770b75-312b2.webp 2x,\\n/static/bp-2c1d7428583927bc8ad4c2f14d770b75-aa8fc.webp 3x\"}}]}}}}]},\"pages\":{\"edges\":[{\"node\":{\"fields\":{\"slug\":\"/about/\",\"prefix\":\"1\"},\"frontmatter\":{\"title\":\"About\",\"menuTitle\":null}}},{\"node\":{\"fields\":{\"slug\":\"/cheatsheets/\",\"prefix\":\"2\"},\"frontmatter\":{\"title\":\"快捷键和命令\",\"menuTitle\":\"Cheatsheet\"}}}]},\"parts\":{\"edges\":[{\"node\":{\"html\":\"<p>我是一名数据工程师，对硬件有浓厚的兴趣。</p>\",\"frontmatter\":{\"title\":\"author\"}}},{\"node\":{\"html\":\"<ul>\\n<li>this is a site built by <a href=\\\"https://www.gatsbyjs.org/\\\">GatsbyJS</a>, ReactJs, CSS in JS</li>\\n<li>delivered by <a href=\\\"https://pages.github.com/\\\">Github Page</a></li>\\n</ul>\",\"frontmatter\":{\"title\":\"footnote\"}}},{\"node\":{\"html\":\"<p>I am a data-science engineer with also interests in React and Hardware. </p>\",\"frontmatter\":{\"title\":\"info\"}}}]}},\"layoutContext\":{}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/layout-index.json\n// module id = 259\n// module chunks = 60335399758886 114276838955818"],"sourceRoot":""}